---
title: "Assignment 1"
subtitle: 'Machine Learning'
author: 'Group I'
output: pdf_document
---
\begin{flushright}

Anna Kurek - 01444623

Linyun Huang - 01379982  


Mark O'Shea - 01384962 


Mingyang Tham - 01428168  


Rejpal Matharu - 01367169  


Yiting Wang - 01423116  
\end{flushright}

&nbsp;

```{r,message=FALSE,warning=FALSE}
library(dplyr)
library(class)
library(xtable)
options(xtable.comment = FALSE)
```

**step 1.** Load the data file.

This dataset contains information on 4898 different white wines, including some aspects of their chemical composition and their quality. 

```{r,warning=FALSE,message=FALSE}
#load the data file and adjust the format
white.raw <- read.csv("winequality-white.csv", header = TRUE, sep = ";")
col_names <- c('fixed acidity',"volatile acidity","citric acid",
               "residual sugar","chlorides",'free sulfur dioxide',
               'total sulfur dioxide',"density","pH","sulphates",
               "alcohol","quality")
colnames(white.raw) <- col_names

```


**step 2.** Create new binary variable.

A new binary variable, goodwine, is created to indicate if the wine is good or not. More specifically, a wine with quality of 6 or higher is indicated as $goodwine=1$.

```{r,message=FALSE,warning=FALSE}
#construct a new binary column ¡°good wine¡± that indicates whether the wine is good 
#(which we define as having a quality of 6 or higher) or not

white.new <- mutate(white.raw, goodwine=ifelse(quality>=6,yes=1,no=0))
white.new$goodwine<- factor(white.new$goodwine, levels = c(1, 0))
```


**step 3.** Normalise the data.

Z-score normalisation is used in this case to avoid the problem of scaling. In this case, the entire dataset is normalised before being splited. More explanation can be found in the python file of the study for red wine.

```{r,message=FALSE,warning=FALSE}
#normalise the data
normalize <- function(x) {return ((x-mean(x)) / (sqrt(sum((x - mean(x))^2)/length(x))))}

nor.white <- as.data.frame(lapply(white.new[1:11],normalize))
col_names <- c('fixed acidity',"volatile acidity","citric acid",
               "residual sugar","chlorides",'free sulfur dioxide',
               'total sulfur dioxide',"density","pH","sulphates",
               "alcohol")
colnames(nor.white) <- col_names
```


**step 4.** Split the data set into a training data set (~40%), a validation data set (~30%) and a test data set (~30%).

```{r}
# The fractions of the dataframe you want to split into training, validation, and test.
fractionTraining   <- 0.40
fractionValidation <- 0.30
fractionTest       <- 0.30

# Computes sample sizes.
sampleSizeTraining   <- floor(fractionTraining   * nrow(white.new))
sampleSizeValidation <- floor(fractionValidation * nrow(white.new))
sampleSizeTest       <- floor(fractionTest       * nrow(white.new))

# Creates the randomly-sampled indices for the dataframe. 
#Usees setdiff() to avoid overlapping subsets of indices.
set.seed(1678)
indicesTraining    <- sort(sample(seq_len(nrow(nor.white)), size=sampleSizeTraining))
indicesNotTraining <- setdiff(seq_len(nrow(nor.white)), indicesTraining)
indicesValidation  <- sort(sample(indicesNotTraining, size=sampleSizeValidation))
indicesTest        <- setdiff(indicesNotTraining, indicesValidation)

# Output the three dataframes for training, validation and test.
white.train   <- nor.white[indicesTraining, ]
white.validation <- nor.white[indicesValidation, ]
white.test       <- nor.white[indicesTest, ]

# Creates labels for the three datasets
train.labels <- white.new[indicesTraining, 13]
validation.labels <- white.new[indicesValidation, 13]
test.labels <- white.new[indicesTest, 13]
```

**step 5.** Loads and trains the k-Nearest Neighbours classifiers for k = 1, .., 80.

**step 6.** Evaluate each classifier on the validation set and selects the best classifier.

The result shows that the best model that returned the highest percentage of correctly classified wines occurred when $k=9$, with an accuracy of $77\%$.

```{r,warning=FALSE,message=FALSE}
range <- 1:80
accuracy <- rep(0,80)

for (k in range){
  pred <- knn(train=white.train,test=white.validation,cl=train.labels,k=k)
  #confustion matrix
  conf_matrix <- table(validation.labels,pred)
  #accuracy
  accuracy[k] <-sum(diag(conf_matrix)/sum(conf_matrix)) 
}

```{r,results='asis',message=FALSE}
#check which k gives the highest accuracy 
a <- data.frame(range,accuracy)
title= c('k','accuracy')
colnames(a) <- title
ordered <- a[order(accuracy,decreasing = TRUE),]
#plot k versus accuracy
plot(range,accuracy,xlab='k')
#print out the highest accuracy and its corresponding k 
print(xtable(head(ordered,1)), include.rownames=FALSE)
```

**step 7.** Predict the generalisation error using the test data set and output the result in a confusion matrix.

The confusion matrix is shown below. Of the 966 wines of good quality in the test set, this model correctly classified 837 of them, and of the 504 wines of non-good quality, the model correctly classified 246 of them. 


Given that good wine was the category of interest, this result indicates that the model has a sensitivity of 87% and a specificity of 51%, for a total accuracy of 77%, thus leading to a generalisation error of 25.5%.

```{r}
#test set
test_set <- knn(train=white.train,test=white.test,cl=train.labels,k=ordered[1,'k'])
conf_matrix_test <- table(test.labels,test_set)
conf_matrix_test
accuracy_test <- sum(diag(conf_matrix_test)/sum(conf_matrix_test))

#generalisation error
1-accuracy_test


```


&nbsp;

In conclusion, the selected prediction model gives a relatively high accuracy compared to the naive model. In a naive model, given the training dataset used, a naive model would predict all wines to be a good wine, as the majority (1305 of 1959) wines in the training data are good wines. Using this prediction, it would have correctly classified 966 of the 1469 wines in the test dataset, for a total accuracy of 65.7%. Therefore, the selected classifier gives a substaintially better prediction result.







